{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b05c16f",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839a485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e7f78",
   "metadata": {},
   "source": [
    "# 1. Tokenizing - Word | Sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76da1f0",
   "metadata": {},
   "source": [
    "1. **Corpus** --> It is defined as collection of documents. It can be thought as just a bunch of text files in a directory, often alongside many other directories of text files.\n",
    "\n",
    "2. **Corpora** --> Body of text\n",
    "\n",
    "3. **Lexicon** --> Word and their meanings\n",
    "\n",
    "4. **Token** --> Each \"entity\" that is a part of whatever was split up based on rules. For eg: each word is a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03f8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Mahendra Singh Dhoni, affectionately known as \"Captain Cool,\" is an iconic figure in Indian cricket.\n",
    "Renowned for his exceptional leadership, agile wicket-keeping skills, and a remarkable ability to finish matches \n",
    "with his bat, Dhoni's impact on the sport is profound. He was the first captain to lead India to victory in the \n",
    "ICC T20 World Cup and to attain the top ranking in Test cricket. Despite his immense success, Dhoni remained humble \n",
    "and down-to-earth, earning respect both on and off the field. His retirement in 2020 marked the end of an era, leaving \n",
    "behind a lasting legacy that continues to inspire cricket enthusiasts and fans worldwide, with his famous \n",
    "\"helicopter shot\" and the Chennai Super Kings' successes in the IPL adding to his legendary status.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60842217",
   "metadata": {},
   "source": [
    "## Sentence Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b42f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nMahendra Singh Dhoni, affectionately known as \"Captain Cool,\" is an iconic figure in Indian cricket.', \"Renowned for his exceptional leadership, agile wicket-keeping skills, and a remarkable ability to finish matches \\nwith his bat, Dhoni's impact on the sport is profound.\", 'He was the first captain to lead India to victory in the \\nICC T20 World Cup and to attain the top ranking in Test cricket.', 'Despite his immense success, Dhoni remained humble \\nand down-to-earth, earning respect both on and off the field.', 'His retirement in 2020 marked the end of an era, leaving \\nbehind a lasting legacy that continues to inspire cricket enthusiasts and fans worldwide, with his famous \\n\"helicopter shot\" and the Chennai Super Kings\\' successes in the IPL adding to his legendary status.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d11fe",
   "metadata": {},
   "source": [
    "## Word Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2836fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mahendra', 'Singh', 'Dhoni', ',', 'affectionately', 'known', 'as', '``', 'Captain', 'Cool', ',', \"''\", 'is', 'an', 'iconic', 'figure', 'in', 'Indian', 'cricket', '.', 'Renowned', 'for', 'his', 'exceptional', 'leadership', ',', 'agile', 'wicket-keeping', 'skills', ',', 'and', 'a', 'remarkable', 'ability', 'to', 'finish', 'matches', 'with', 'his', 'bat', ',', 'Dhoni', \"'s\", 'impact', 'on', 'the', 'sport', 'is', 'profound', '.', 'He', 'was', 'the', 'first', 'captain', 'to', 'lead', 'India', 'to', 'victory', 'in', 'the', 'ICC', 'T20', 'World', 'Cup', 'and', 'to', 'attain', 'the', 'top', 'ranking', 'in', 'Test', 'cricket', '.', 'Despite', 'his', 'immense', 'success', ',', 'Dhoni', 'remained', 'humble', 'and', 'down-to-earth', ',', 'earning', 'respect', 'both', 'on', 'and', 'off', 'the', 'field', '.', 'His', 'retirement', 'in', '2020', 'marked', 'the', 'end', 'of', 'an', 'era', ',', 'leaving', 'behind', 'a', 'lasting', 'legacy', 'that', 'continues', 'to', 'inspire', 'cricket', 'enthusiasts', 'and', 'fans', 'worldwide', ',', 'with', 'his', 'famous', \"''\", 'helicopter', 'shot', \"''\", 'and', 'the', 'Chennai', 'Super', 'Kings', \"'\", 'successes', 'in', 'the', 'IPL', 'adding', 'to', 'his', 'legendary', 'status', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1d024",
   "metadata": {},
   "source": [
    "# 2. Stopwords \n",
    "\n",
    "Stopwords are the words in any language which does not add much meaning to a sentence. They can be ignored without sacrificing their meaning of the sentence. Ex: 'is','are', 'at'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cc1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e505f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'for', 'into', 'yours', 'him', 'what', 'do', 'theirs', \"weren't\", 'myself', 'a', 'ourselves', 'on', 'o', 'then', 'an', 'when', 'those', 'any', 'both', 'm', 'as', 'the', \"you've\", 'through', 'didn', 'be', \"shan't\", 'same', 'shouldn', 'wouldn', \"haven't\", 'most', 'had', \"mightn't\", 'her', 'you', 'she', 'because', \"doesn't\", 'is', 'too', 'now', 've', 'very', 'if', 'our', 'this', 'between', 'yourself', \"wasn't\", 'under', \"shouldn't\", 'until', 'with', 'couldn', 'have', 'did', 'so', 'over', 'all', 'has', 'doing', 'wasn', 'been', 'his', 'it', 'not', 'y', 'by', 'ours', 'about', 'itself', 'ain', 'was', 're', 'shan', \"it's\", 'off', 'while', 'themselves', 'during', 't', 'don', 'aren', 'only', \"hasn't\", 'in', 'himself', \"you'd\", 'their', 'or', 'down', 'but', 'and', 'yourselves', 'my', 'mightn', 'needn', 'own', 'll', 'to', 'some', 'why', 'its', 'hadn', 'd', \"aren't\", 'can', \"should've\", 'where', \"that'll\", 'won', 'which', 'up', 'weren', 'these', \"don't\", 'other', 'hers', 'against', 'am', 'whom', 'that', 'will', 'below', 'hasn', 'he', 'having', 'they', \"hadn't\", \"mustn't\", 'again', 'them', 'isn', \"needn't\", \"you're\", 'your', 'few', 'such', 'nor', 'more', 'being', 'me', 'before', \"wouldn't\", 'further', 'out', 'after', 'there', 'at', 'each', 'here', 'herself', \"you'll\", 'from', 'above', 'ma', 'we', 'than', 'i', 'mustn', \"isn't\", \"she's\", 'were', 'how', 'once', 'of', \"didn't\", 'doesn', 'does', \"won't\", 'just', 'are', 'haven', 'should', 'no', 's', 'who', \"couldn't\"}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89a508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mahendra', 'Singh', 'Dhoni', ',', 'affectionately', 'known', '``', 'Captain', 'Cool', ',', \"''\", 'iconic', 'figure', 'Indian', 'cricket', '.', 'Renowned', 'exceptional', 'leadership', ',', 'agile', 'wicket-keeping', 'skills', ',', 'remarkable', 'ability', 'finish', 'matches', 'bat', ',', 'Dhoni', \"'s\", 'impact', 'sport', 'profound', '.', 'He', 'first', 'captain', 'lead', 'India', 'victory', 'ICC', 'T20', 'World', 'Cup', 'attain', 'top', 'ranking', 'Test', 'cricket', '.', 'Despite', 'immense', 'success', ',', 'Dhoni', 'remained', 'humble', 'down-to-earth', ',', 'earning', 'respect', 'field', '.', 'His', 'retirement', '2020', 'marked', 'end', 'era', ',', 'leaving', 'behind', 'lasting', 'legacy', 'continues', 'inspire', 'cricket', 'enthusiasts', 'fans', 'worldwide', ',', 'famous', \"''\", 'helicopter', 'shot', \"''\", 'Chennai', 'Super', 'Kings', \"'\", 'successes', 'IPL', 'adding', 'legendary', 'status', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sample_text)\n",
    "\n",
    "filter_sentence = []\n",
    "\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        filter_sentence.append(word)\n",
    "    \n",
    "print(filter_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cb54d",
   "metadata": {},
   "source": [
    "# 3. Stemming \n",
    "\n",
    "This is known as sort of normalizing method. Many variations of words carry the same meaning, other than when tense is involved.\n",
    "\n",
    "The reason why we stem is to shorten the lookup, and normalize sentences.\n",
    "\n",
    "Eg: I was taking a ride in the car. I was riding in the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b08bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0293f130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "phthone\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "sam_words = [\"python\", \"pythoner\", \"pythoning\", \"phthoned\", \"pythonly\"]\n",
    "\n",
    "for word in sam_words:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c01c4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'import',\n",
       " 'to',\n",
       " 'be',\n",
       " 'pythoniy',\n",
       " 'while',\n",
       " 'you',\n",
       " 'are',\n",
       " 'python',\n",
       " 'with',\n",
       " 'python',\n",
       " '.',\n",
       " 'all',\n",
       " 'python',\n",
       " 'have',\n",
       " 'python',\n",
       " 'poorli',\n",
       " 'atleast',\n",
       " 'onc',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = \"It is very important to be pythoniy while you are pythoning with python. All pythoners have pythoned poorly atleast once.\"\n",
    "\n",
    "words = word_tokenize(sam)\n",
    "\n",
    "output = []\n",
    "\n",
    "for word in words:\n",
    "    output.append(ps.stem(word))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bc3f1",
   "metadata": {},
   "source": [
    "# 4. Part of speech tagging \n",
    "\n",
    "Labeling the words as sentences and nouns, adejectives, verbs etc. Even more impressive, it also labels by tense and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e9c6b",
   "metadata": {},
   "source": [
    "#### POS tag list:\n",
    "\n",
    "CC coordinating conjunction\n",
    "\n",
    "CD cardinal digit\n",
    "\n",
    "DT determiner\n",
    "\n",
    "EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "\n",
    "FW foreign word\n",
    "\n",
    "IN preposition/subordinating conjunction\n",
    "\n",
    "JJ adjective 'big'\n",
    "\n",
    "JJR adjective, comparative 'bigger'\n",
    "\n",
    "JJS adjective, superlative 'biggest'\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "\n",
    "NN noun, singular 'desk'\n",
    "\n",
    "NNS noun plural 'desks'\n",
    "\n",
    "NNP proper noun, singular 'Harrison'\n",
    "\n",
    "NNPS proper noun, plural 'Americans'\n",
    "\n",
    "PDT predeterminer 'all the kids'\n",
    "\n",
    "POS possessive ending parent\\'s\n",
    "\n",
    "PRP personal pronoun I, he, she\n",
    "\n",
    "RB adverb very, silently,\n",
    "\n",
    "RBR adverb, comparative better\n",
    "\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "\n",
    "TO to go 'to' the store.\n",
    "\n",
    "UH interjection errrrrrrrm\n",
    "\n",
    "VB verb, base form take\n",
    "\n",
    "VBD verb, past tense took\n",
    "\n",
    "VBG verb, gerund/present participle taking\n",
    "\n",
    "VBN verb, past participle taken\n",
    "\n",
    "VBP verb, sing. present, non-3d take\n",
    "\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "\n",
    "WDT wh-determiner which\n",
    "\n",
    "WP wh-pronoun who, what\n",
    "\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4008a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6adb07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"Engineers, as practitioners of engineering, are professionals who invent, design, analyze, build and test machines, complex systems, structures, gadgets and materials to fulfill functional objectives and requirements while considering the limitations imposed by practicality, regulation, safety and cost.[1][2] The word engineer (Latin ingeniator[3]) is derived from the Latin words ingeniare (to create, generate, contrive, devise and ingenium) (cleverness).[4][5] The foundational qualifications of an engineer typically include a four-year bachelor's degree in an engineering discipline, or in some jurisdictions, a master's degree in an engineering discipline plus four to six years of peer-reviewed professional practice (culminating in a project report or thesis) and passage of engineering board examinations.The work of engineers forms the link between scientific discoveries and their subsequent applications to human and business needs and quality of life.[1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16e883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States, in the 1970s. NLP's creators claim there is a connection between neurological processes (neuro-), language (linguistic) and behavioral patterns learned through experience (programming), and that these can be changed to achieve specific goals in life.[1][2]: 2  Bandler and Grinder also claim that NLP methodology can model the skills of exceptional people, allowing anyone to acquire those skills.[3]: 5–6 [4] They claim as well that, often in a single session, NLP can treat problems such as phobias, depression, tic disorders, psychosomatic illnesses, near-sightedness,[5] allergy, the common cold,[Note 1] and learning disorders.[7][8] NLP has been adopted by some hypnotherapists and also by companies that run seminars marketed as leadership training to businesses and government agencies.[9][10]There is no scientific evidence supporting the claims made by NLP advocates, and it has been discredited as a pseudoscience.[11][12][13] Scientific reviews state that NLP is based on outdated metaphors of how the brain works that are inconsistent with current neurological theory and contain numerous factual errors. [10][14] Reviews also found that all of the supportive research on NLP contained significant methodological flaws and that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, Grinder, and other NLP practitioners.[12][13]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a3684ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sentence_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sentence_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9f0b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States, in the 1970s.',\n",
       " \"NLP's creators claim there is a connection between neurological processes (neuro-), language (linguistic) and behavioral patterns learned through experience (programming), and that these can be changed to achieve specific goals in life.\",\n",
       " '[1][2]:\\u200a2\\u200a Bandler and Grinder also claim that NLP methodology can model the skills of exceptional people, allowing anyone to acquire those skills.',\n",
       " '[3]:\\u200a5–6\\u200a[4] They claim as well that, often in a single session, NLP can treat problems such as phobias, depression, tic disorders, psychosomatic illnesses, near-sightedness,[5] allergy, the common cold,[Note 1] and learning disorders.',\n",
       " '[7][8] NLP has been adopted by some hypnotherapists and also by companies that run seminars marketed as leadership training to businesses and government agencies.',\n",
       " '[9][10]There is no scientific evidence supporting the claims made by NLP advocates, and it has been discredited as a pseudoscience.',\n",
       " '[11][12][13] Scientific reviews state that NLP is based on outdated metaphors of how the brain works that are inconsistent with current neurological theory and contain numerous factual errors.',\n",
       " '[10][14] Reviews also found that all of the supportive research on NLP contained significant methodological flaws and that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, Grinder, and other NLP practitioners.',\n",
       " '[12][13]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdda8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Neuro-linguistic', 'JJ'), ('programming', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('pseudoscientific', 'JJ'), ('approach', 'NN'), ('to', 'TO'), ('communication', 'NN'), (',', ','), ('personal', 'JJ'), ('development', 'NN'), (',', ','), ('and', 'CC'), ('psychotherapy', 'RB'), ('created', 'VBN'), ('by', 'IN'), ('Richard', 'NNP'), ('Bandler', 'NNP'), ('and', 'CC'), ('John', 'NNP'), ('Grinder', 'NNP'), ('in', 'IN'), ('California', 'NNP'), (',', ','), ('United', 'NNP'), ('States', 'NNPS'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('1970s', 'CD'), ('.', '.')]\n",
      "[('NLP', 'NNP'), (\"'s\", 'POS'), ('creators', 'NNS'), ('claim', 'VBP'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('connection', 'NN'), ('between', 'IN'), ('neurological', 'JJ'), ('processes', 'NNS'), ('(', '('), ('neuro-', 'JJ'), (')', ')'), (',', ','), ('language', 'NN'), ('(', '('), ('linguistic', 'JJ'), (')', ')'), ('and', 'CC'), ('behavioral', 'JJ'), ('patterns', 'NNS'), ('learned', 'VBD'), ('through', 'IN'), ('experience', 'NN'), ('(', '('), ('programming', 'VBG'), (')', ')'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('these', 'DT'), ('can', 'MD'), ('be', 'VB'), ('changed', 'VBN'), ('to', 'TO'), ('achieve', 'VB'), ('specific', 'JJ'), ('goals', 'NNS'), ('in', 'IN'), ('life', 'NN'), ('.', '.')]\n",
      "[('[', 'RB'), ('1', 'CD'), (']', 'JJ'), ('[', '$'), ('2', 'CD'), (']', 'NN'), (':', ':'), ('2', 'CD'), ('Bandler', 'NNP'), ('and', 'CC'), ('Grinder', 'NNP'), ('also', 'RB'), ('claim', 'VBP'), ('that', 'IN'), ('NLP', 'NNP'), ('methodology', 'NN'), ('can', 'MD'), ('model', 'VB'), ('the', 'DT'), ('skills', 'NNS'), ('of', 'IN'), ('exceptional', 'JJ'), ('people', 'NNS'), (',', ','), ('allowing', 'VBG'), ('anyone', 'NN'), ('to', 'TO'), ('acquire', 'VB'), ('those', 'DT'), ('skills', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('3', 'CD'), (']', 'NNS'), (':', ':'), ('5–6', 'CD'), ('[', '$'), ('4', 'CD'), (']', 'NN'), ('They', 'PRP'), ('claim', 'VBP'), ('as', 'RB'), ('well', 'RB'), ('that', 'IN'), (',', ','), ('often', 'RB'), ('in', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('session', 'NN'), (',', ','), ('NLP', 'NNP'), ('can', 'MD'), ('treat', 'VB'), ('problems', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('phobias', 'NNS'), (',', ','), ('depression', 'NN'), (',', ','), ('tic', 'JJ'), ('disorders', 'NNS'), (',', ','), ('psychosomatic', 'JJ'), ('illnesses', 'NNS'), (',', ','), ('near-sightedness', 'JJ'), (',', ','), ('[', 'JJ'), ('5', 'CD'), (']', 'NN'), ('allergy', 'NN'), (',', ','), ('the', 'DT'), ('common', 'JJ'), ('cold', 'NN'), (',', ','), ('[', 'NNP'), ('Note', 'NNP'), ('1', 'CD'), (']', 'NN'), ('and', 'CC'), ('learning', 'NN'), ('disorders', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('7', 'CD'), (']', 'JJ'), ('[', '$'), ('8', 'CD'), (']', 'NNP'), ('NLP', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('adopted', 'VBN'), ('by', 'IN'), ('some', 'DT'), ('hypnotherapists', 'NNS'), ('and', 'CC'), ('also', 'RB'), ('by', 'IN'), ('companies', 'NNS'), ('that', 'WDT'), ('run', 'VBP'), ('seminars', 'RB'), ('marketed', 'VBN'), ('as', 'IN'), ('leadership', 'NN'), ('training', 'NN'), ('to', 'TO'), ('businesses', 'NNS'), ('and', 'CC'), ('government', 'NN'), ('agencies', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('9', 'CD'), (']', 'JJ'), ('[', '$'), ('10', 'CD'), (']', 'NN'), ('There', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('scientific', 'JJ'), ('evidence', 'NN'), ('supporting', 'VBG'), ('the', 'DT'), ('claims', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('NLP', 'NNP'), ('advocates', 'NNS'), (',', ','), ('and', 'CC'), ('it', 'PRP'), ('has', 'VBZ'), ('been', 'VBN'), ('discredited', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('pseudoscience', 'NN'), ('.', '.')]\n",
      "[('[', 'RB'), ('11', 'CD'), (']', 'JJ'), ('[', '$'), ('12', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('13', 'CD'), (']', 'NNP'), ('Scientific', 'NNP'), ('reviews', 'VBZ'), ('state', 'NN'), ('that', 'IN'), ('NLP', 'NNP'), ('is', 'VBZ'), ('based', 'VBN'), ('on', 'IN'), ('outdated', 'JJ'), ('metaphors', 'NNS'), ('of', 'IN'), ('how', 'WRB'), ('the', 'DT'), ('brain', 'NN'), ('works', 'VBZ'), ('that', 'WDT'), ('are', 'VBP'), ('inconsistent', 'JJ'), ('with', 'IN'), ('current', 'JJ'), ('neurological', 'JJ'), ('theory', 'NN'), ('and', 'CC'), ('contain', 'VBP'), ('numerous', 'JJ'), ('factual', 'JJ'), ('errors', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('10', 'CD'), (']', 'JJ'), ('[', '$'), ('14', 'CD'), (']', 'NNP'), ('Reviews', 'NNP'), ('also', 'RB'), ('found', 'VBD'), ('that', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('supportive', 'JJ'), ('research', 'NN'), ('on', 'IN'), ('NLP', 'NNP'), ('contained', 'VBD'), ('significant', 'JJ'), ('methodological', 'JJ'), ('flaws', 'NNS'), ('and', 'CC'), ('that', 'IN'), ('there', 'EX'), ('were', 'VBD'), ('three', 'CD'), ('times', 'NNS'), ('as', 'IN'), ('many', 'JJ'), ('studies', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('much', 'JJ'), ('higher', 'JJR'), ('quality', 'NN'), ('that', 'WDT'), ('failed', 'VBD'), ('to', 'TO'), ('reproduce', 'VB'), ('the', 'DT'), ('extraordinary', 'JJ'), ('claims', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('Bandler', 'NNP'), (',', ','), ('Grinder', 'NNP'), (',', ','), ('and', 'CC'), ('other', 'JJ'), ('NLP', 'NNP'), ('practitioners', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('12', 'CD'), (']', 'JJ'), ('[', '$'), ('13', 'CD'), (']', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for word in tokenized:\n",
    "            words = nltk.word_tokenize(word)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb07ee5",
   "metadata": {},
   "source": [
    "# 5. Chunking\n",
    "\n",
    "Group the words in to meaningful chunks. Main goals of chunking is \"Noun phrases\". These are phrases of one or more words that contain a noun, maybe some descriptive words, maybe a verb, and maybe something like an adverb. The idea is to group nouns with tht words that are relation to them.\n",
    "\n",
    "In order to chunk, we combine the part of speech tags wth regular expression. Mainly from regular expression, we are going to utilize the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52dd8e",
   "metadata": {},
   "source": [
    "### _Identifier_\n",
    "\n",
    "1. \\d - any number\n",
    "2. \\D - anything but a number\n",
    "3. \\s - space\n",
    "4. \\S - anything but a space\n",
    "5. \\w - any letter \n",
    "6. \\W - anything but a letter\n",
    "7. . - any character, except for a new line\n",
    "8. \\b - space around whole words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de53a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Neuro-linguistic/JJ\n",
      "  programming/NN\n",
      "  (/(\n",
      "  (Chunk NLP/NNP)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pseudoscientific/JJ\n",
      "  approach/NN\n",
      "  to/TO\n",
      "  communication/NN\n",
      "  ,/,\n",
      "  personal/JJ\n",
      "  development/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  psychotherapy/RB\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (Chunk Richard/NNP Bandler/NNP)\n",
      "  and/CC\n",
      "  (Chunk John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (Chunk California/NNP)\n",
      "  ,/,\n",
      "  (Chunk United/NNP)\n",
      "  States/NNPS\n",
      "  ,/,\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1970s/CD\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk NLP/NNP)\n",
      "  's/POS\n",
      "  creators/NNS\n",
      "  claim/VBP\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  connection/NN\n",
      "  between/IN\n",
      "  neurological/JJ\n",
      "  processes/NNS\n",
      "  (/(\n",
      "  neuro-/JJ\n",
      "  )/)\n",
      "  ,/,\n",
      "  language/NN\n",
      "  (/(\n",
      "  linguistic/JJ\n",
      "  )/)\n",
      "  and/CC\n",
      "  behavioral/JJ\n",
      "  patterns/NNS\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  experience/NN\n",
      "  (/(\n",
      "  programming/VBG\n",
      "  )/)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  that/IN\n",
      "  these/DT\n",
      "  can/MD\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  specific/JJ\n",
      "  goals/NNS\n",
      "  in/IN\n",
      "  life/NN\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  1/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  2/CD\n",
      "  ]/NN\n",
      "  :/:\n",
      "  2/CD\n",
      "  (Chunk Bandler/NNP)\n",
      "  and/CC\n",
      "  (Chunk Grinder/NNP)\n",
      "  also/RB\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP methodology/NN)\n",
      "  can/MD\n",
      "  model/VB\n",
      "  the/DT\n",
      "  skills/NNS\n",
      "  of/IN\n",
      "  exceptional/JJ\n",
      "  people/NNS\n",
      "  ,/,\n",
      "  allowing/VBG\n",
      "  anyone/NN\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  skills/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  3/CD\n",
      "  ]/NNS\n",
      "  :/:\n",
      "  5–6/CD\n",
      "  [/$\n",
      "  4/CD\n",
      "  ]/NN\n",
      "  They/PRP\n",
      "  claim/VBP\n",
      "  as/RB\n",
      "  well/RB\n",
      "  that/IN\n",
      "  ,/,\n",
      "  often/RB\n",
      "  in/IN\n",
      "  a/DT\n",
      "  single/JJ\n",
      "  session/NN\n",
      "  ,/,\n",
      "  (Chunk NLP/NNP)\n",
      "  can/MD\n",
      "  treat/VB\n",
      "  problems/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  phobias/NNS\n",
      "  ,/,\n",
      "  depression/NN\n",
      "  ,/,\n",
      "  tic/JJ\n",
      "  disorders/NNS\n",
      "  ,/,\n",
      "  psychosomatic/JJ\n",
      "  illnesses/NNS\n",
      "  ,/,\n",
      "  near-sightedness/JJ\n",
      "  ,/,\n",
      "  [/JJ\n",
      "  5/CD\n",
      "  ]/NN\n",
      "  allergy/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  common/JJ\n",
      "  cold/NN\n",
      "  ,/,\n",
      "  (Chunk [/NNP Note/NNP)\n",
      "  1/CD\n",
      "  ]/NN\n",
      "  and/CC\n",
      "  learning/NN\n",
      "  disorders/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  7/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  8/CD\n",
      "  (Chunk ]/NNP NLP/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  hypnotherapists/NNS\n",
      "  and/CC\n",
      "  also/RB\n",
      "  by/IN\n",
      "  companies/NNS\n",
      "  that/WDT\n",
      "  run/VBP\n",
      "  seminars/RB\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  leadership/NN\n",
      "  training/NN\n",
      "  to/TO\n",
      "  businesses/NNS\n",
      "  and/CC\n",
      "  government/NN\n",
      "  agencies/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  9/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  10/CD\n",
      "  ]/NN\n",
      "  There/EX\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  scientific/JJ\n",
      "  evidence/NN\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  advocates/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  pseudoscience/NN\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  11/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  12/CD\n",
      "  (Chunk ]/NNP)\n",
      "  [/VBD\n",
      "  13/CD\n",
      "  (Chunk ]/NNP Scientific/NNP)\n",
      "  reviews/VBZ\n",
      "  state/NN\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  outdated/JJ\n",
      "  metaphors/NNS\n",
      "  of/IN\n",
      "  how/WRB\n",
      "  the/DT\n",
      "  brain/NN\n",
      "  works/VBZ\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  inconsistent/JJ\n",
      "  with/IN\n",
      "  current/JJ\n",
      "  neurological/JJ\n",
      "  theory/NN\n",
      "  and/CC\n",
      "  contain/VBP\n",
      "  numerous/JJ\n",
      "  factual/JJ\n",
      "  errors/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  10/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  14/CD\n",
      "  (Chunk ]/NNP Reviews/NNP)\n",
      "  also/RB\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  supportive/JJ\n",
      "  research/NN\n",
      "  on/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  contained/VBD\n",
      "  significant/JJ\n",
      "  methodological/JJ\n",
      "  flaws/NNS\n",
      "  and/CC\n",
      "  that/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  three/CD\n",
      "  times/NNS\n",
      "  as/IN\n",
      "  many/JJ\n",
      "  studies/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  much/JJ\n",
      "  higher/JJR\n",
      "  quality/NN\n",
      "  that/WDT\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  extraordinary/JJ\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk Bandler/NNP)\n",
      "  ,/,\n",
      "  (Chunk Grinder/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  (Chunk NLP/NNP)\n",
      "  practitioners/NNS\n",
      "  ./.)\n",
      "(S [/RB 12/CD ]/JJ [/$ 13/CD ]/NN)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\" \n",
    "            \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            print(chunked)\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01f5f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de66018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            #print(tagged)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\" \n",
    "            \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            #print(chunked)\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84bb88",
   "metadata": {},
   "source": [
    "# 6. Chinking \n",
    "\n",
    "It is not like chinking, it is basically a way for you to remove a chunk from a chunk. The chunk that you remove from your chunk is chink."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55066d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Chunk Neuro-linguistic/JJ programming/NN (/( NLP/NNP )/))\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  (Chunk pseudoscientific/JJ approach/NN)\n",
      "  to/TO\n",
      "  (Chunk\n",
      "    communication/NN\n",
      "    ,/,\n",
      "    personal/JJ\n",
      "    development/NN\n",
      "    ,/,\n",
      "    and/CC\n",
      "    psychotherapy/RB)\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (Chunk Richard/NNP Bandler/NNP and/CC John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (Chunk California/NNP ,/, United/NNP States/NNPS ,/,)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (Chunk 1970s/CD ./.))\n",
      "(S\n",
      "  (Chunk NLP/NNP 's/POS creators/NNS)\n",
      "  claim/VBP\n",
      "  (Chunk there/EX)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  (Chunk connection/NN)\n",
      "  between/IN\n",
      "  (Chunk\n",
      "    neurological/JJ\n",
      "    processes/NNS\n",
      "    (/(\n",
      "    neuro-/JJ\n",
      "    )/)\n",
      "    ,/,\n",
      "    language/NN\n",
      "    (/(\n",
      "    linguistic/JJ\n",
      "    )/)\n",
      "    and/CC\n",
      "    behavioral/JJ\n",
      "    patterns/NNS)\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  (Chunk experience/NN (/()\n",
      "  programming/VBG\n",
      "  (Chunk )/) ,/, and/CC)\n",
      "  that/IN\n",
      "  these/DT\n",
      "  (Chunk can/MD)\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  (Chunk specific/JJ goals/NNS)\n",
      "  in/IN\n",
      "  (Chunk life/NN ./.))\n",
      "(S\n",
      "  (Chunk\n",
      "    [/RB\n",
      "    1/CD\n",
      "    ]/JJ\n",
      "    [/$\n",
      "    2/CD\n",
      "    ]/NN\n",
      "    :/:\n",
      "    2/CD\n",
      "    Bandler/NNP\n",
      "    and/CC\n",
      "    Grinder/NNP\n",
      "    also/RB)\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP methodology/NN can/MD)\n",
      "  model/VB\n",
      "  the/DT\n",
      "  (Chunk skills/NNS)\n",
      "  of/IN\n",
      "  (Chunk exceptional/JJ people/NNS ,/,)\n",
      "  allowing/VBG\n",
      "  (Chunk anyone/NN)\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  (Chunk skills/NNS ./.))\n",
      "(S\n",
      "  (Chunk [/RB 3/CD ]/NNS :/: 5–6/CD [/$ 4/CD ]/NN They/PRP)\n",
      "  claim/VBP\n",
      "  (Chunk as/RB well/RB)\n",
      "  that/IN\n",
      "  (Chunk ,/, often/RB)\n",
      "  in/IN\n",
      "  a/DT\n",
      "  (Chunk single/JJ session/NN ,/, NLP/NNP can/MD)\n",
      "  treat/VB\n",
      "  (Chunk problems/NNS such/JJ)\n",
      "  as/IN\n",
      "  (Chunk\n",
      "    phobias/NNS\n",
      "    ,/,\n",
      "    depression/NN\n",
      "    ,/,\n",
      "    tic/JJ\n",
      "    disorders/NNS\n",
      "    ,/,\n",
      "    psychosomatic/JJ\n",
      "    illnesses/NNS\n",
      "    ,/,\n",
      "    near-sightedness/JJ\n",
      "    ,/,\n",
      "    [/JJ\n",
      "    5/CD\n",
      "    ]/NN\n",
      "    allergy/NN\n",
      "    ,/,)\n",
      "  the/DT\n",
      "  (Chunk\n",
      "    common/JJ\n",
      "    cold/NN\n",
      "    ,/,\n",
      "    [/NNP\n",
      "    Note/NNP\n",
      "    1/CD\n",
      "    ]/NN\n",
      "    and/CC\n",
      "    learning/NN\n",
      "    disorders/NNS\n",
      "    ./.))\n",
      "(S\n",
      "  (Chunk [/RB 7/CD ]/JJ [/$ 8/CD ]/NNP NLP/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  (Chunk hypnotherapists/NNS and/CC also/RB)\n",
      "  by/IN\n",
      "  (Chunk companies/NNS that/WDT)\n",
      "  run/VBP\n",
      "  (Chunk seminars/RB)\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  (Chunk leadership/NN training/NN)\n",
      "  to/TO\n",
      "  (Chunk businesses/NNS and/CC government/NN agencies/NNS ./.))\n",
      "(S\n",
      "  (Chunk [/RB 9/CD ]/JJ [/$ 10/CD ]/NN There/EX)\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  (Chunk scientific/JJ evidence/NN)\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  (Chunk claims/NNS)\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk NLP/NNP advocates/NNS ,/, and/CC it/PRP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  (Chunk pseudoscience/NN ./.))\n",
      "(S\n",
      "  (Chunk [/RB 11/CD ]/JJ [/$ 12/CD ]/NNP)\n",
      "  [/VBD\n",
      "  (Chunk 13/CD ]/NNP Scientific/NNP)\n",
      "  reviews/VBZ\n",
      "  (Chunk state/NN)\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  (Chunk outdated/JJ metaphors/NNS)\n",
      "  of/IN\n",
      "  (Chunk how/WRB)\n",
      "  the/DT\n",
      "  (Chunk brain/NN)\n",
      "  works/VBZ\n",
      "  (Chunk that/WDT)\n",
      "  are/VBP\n",
      "  (Chunk inconsistent/JJ)\n",
      "  with/IN\n",
      "  (Chunk current/JJ neurological/JJ theory/NN and/CC)\n",
      "  contain/VBP\n",
      "  (Chunk numerous/JJ factual/JJ errors/NNS ./.))\n",
      "(S\n",
      "  (Chunk [/RB 10/CD ]/JJ [/$ 14/CD ]/NNP Reviews/NNP also/RB)\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  (Chunk supportive/JJ research/NN)\n",
      "  on/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  contained/VBD\n",
      "  (Chunk significant/JJ methodological/JJ flaws/NNS and/CC)\n",
      "  that/IN\n",
      "  (Chunk there/EX)\n",
      "  were/VBD\n",
      "  (Chunk three/CD times/NNS)\n",
      "  as/IN\n",
      "  (Chunk many/JJ studies/NNS)\n",
      "  of/IN\n",
      "  a/DT\n",
      "  (Chunk much/JJ higher/JJR quality/NN that/WDT)\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  (Chunk extraordinary/JJ claims/NNS)\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk\n",
      "    Bandler/NNP\n",
      "    ,/,\n",
      "    Grinder/NNP\n",
      "    ,/,\n",
      "    and/CC\n",
      "    other/JJ\n",
      "    NLP/NNP\n",
      "    practitioners/NNS\n",
      "    ./.))\n",
      "(S (Chunk [/RB 12/CD ]/JJ [/$ 13/CD ]/NN))\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<.*>+}\n",
    "                                    }<VB.?|IN|DT|TO>+{\"\"\"\n",
    "            \n",
    "            chunkparser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkparser.parse(tagged)\n",
    "            print(chunked)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "            \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bb080",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
