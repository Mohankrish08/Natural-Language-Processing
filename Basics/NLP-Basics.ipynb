{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b05c16f",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "839a485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581e7f78",
   "metadata": {},
   "source": [
    "# 1. Tokenizing - Word | Sentence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76da1f0",
   "metadata": {},
   "source": [
    "1. **Corpus** --> It is defined as collection of documents. It can be thought as just a bunch of text files in a directory, often alongside many other directories of text files.\n",
    "\n",
    "2. **Corpora** --> Body of text\n",
    "\n",
    "3. **Lexicon** --> Word and their meanings\n",
    "\n",
    "4. **Token** --> Each \"entity\" that is a part of whatever was split up based on rules. For eg: each word is a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03f8d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Mahendra Singh Dhoni, affectionately known as \"Captain Cool,\" is an iconic figure in Indian cricket.\n",
    "Renowned for his exceptional leadership, agile wicket-keeping skills, and a remarkable ability to finish matches \n",
    "with his bat, Dhoni's impact on the sport is profound. He was the first captain to lead India to victory in the \n",
    "ICC T20 World Cup and to attain the top ranking in Test cricket. Despite his immense success, Dhoni remained humble \n",
    "and down-to-earth, earning respect both on and off the field. His retirement in 2020 marked the end of an era, leaving \n",
    "behind a lasting legacy that continues to inspire cricket enthusiasts and fans worldwide, with his famous \n",
    "\"helicopter shot\" and the Chennai Super Kings' successes in the IPL adding to his legendary status.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60842217",
   "metadata": {},
   "source": [
    "## Sentence Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b42f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nMahendra Singh Dhoni, affectionately known as \"Captain Cool,\" is an iconic figure in Indian cricket.', \"Renowned for his exceptional leadership, agile wicket-keeping skills, and a remarkable ability to finish matches \\nwith his bat, Dhoni's impact on the sport is profound.\", 'He was the first captain to lead India to victory in the \\nICC T20 World Cup and to attain the top ranking in Test cricket.', 'Despite his immense success, Dhoni remained humble \\nand down-to-earth, earning respect both on and off the field.', 'His retirement in 2020 marked the end of an era, leaving \\nbehind a lasting legacy that continues to inspire cricket enthusiasts and fans worldwide, with his famous \\n\"helicopter shot\" and the Chennai Super Kings\\' successes in the IPL adding to his legendary status.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d11fe",
   "metadata": {},
   "source": [
    "## Word Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2836fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mahendra', 'Singh', 'Dhoni', ',', 'affectionately', 'known', 'as', '``', 'Captain', 'Cool', ',', \"''\", 'is', 'an', 'iconic', 'figure', 'in', 'Indian', 'cricket', '.', 'Renowned', 'for', 'his', 'exceptional', 'leadership', ',', 'agile', 'wicket-keeping', 'skills', ',', 'and', 'a', 'remarkable', 'ability', 'to', 'finish', 'matches', 'with', 'his', 'bat', ',', 'Dhoni', \"'s\", 'impact', 'on', 'the', 'sport', 'is', 'profound', '.', 'He', 'was', 'the', 'first', 'captain', 'to', 'lead', 'India', 'to', 'victory', 'in', 'the', 'ICC', 'T20', 'World', 'Cup', 'and', 'to', 'attain', 'the', 'top', 'ranking', 'in', 'Test', 'cricket', '.', 'Despite', 'his', 'immense', 'success', ',', 'Dhoni', 'remained', 'humble', 'and', 'down-to-earth', ',', 'earning', 'respect', 'both', 'on', 'and', 'off', 'the', 'field', '.', 'His', 'retirement', 'in', '2020', 'marked', 'the', 'end', 'of', 'an', 'era', ',', 'leaving', 'behind', 'a', 'lasting', 'legacy', 'that', 'continues', 'to', 'inspire', 'cricket', 'enthusiasts', 'and', 'fans', 'worldwide', ',', 'with', 'his', 'famous', \"''\", 'helicopter', 'shot', \"''\", 'and', 'the', 'Chennai', 'Super', 'Kings', \"'\", 'successes', 'in', 'the', 'IPL', 'adding', 'to', 'his', 'legendary', 'status', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sample_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1d024",
   "metadata": {},
   "source": [
    "# 2. Stopwords \n",
    "\n",
    "Stopwords are the words in any language which does not add much meaning to a sentence. They can be ignored without sacrificing their meaning of the sentence. Ex: 'is','are', 'at'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cc1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e505f386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'be', \"you're\", 'it', 'which', 'weren', 'too', 'have', 'some', 'other', 'there', 'down', 'where', 'those', \"shouldn't\", 'as', 'not', 'or', \"doesn't\", 'up', \"she's\", 'you', 'before', 'aren', 'hasn', 'do', 'more', 'are', 'through', 'll', 'what', 'further', 'no', 'then', 'than', 'y', 'couldn', 'all', 'will', 'out', \"needn't\", 'ours', 'who', 'having', 'ma', 'such', 'was', 'on', 'whom', 'hers', 'only', 'wasn', 'until', 'below', 'him', \"isn't\", 'mustn', 'he', 'needn', 'into', 'had', \"you'd\", 'herself', 'itself', 'any', 'once', 'again', 'haven', 'about', 'now', 'most', 'ain', \"mightn't\", 'few', 'shouldn', 'both', 'has', 'o', 'hadn', \"wasn't\", 'himself', \"should've\", \"that'll\", 'a', 've', \"won't\", 'that', 'but', 'under', 'were', 'after', 'they', \"it's\", 'against', 'm', 'doesn', 'ourselves', 'don', 'between', 's', 'each', 'by', 'their', 'so', 'my', 'here', 'myself', 'an', 'over', 'this', 'very', \"hasn't\", 'shan', \"mustn't\", 're', 'being', 'should', \"wouldn't\", 'with', 'i', 'her', 'yourselves', 'his', 'in', 'own', 'd', 'themselves', 'theirs', 'doing', 'of', \"don't\", 'for', 'yourself', 'from', 'does', 'while', 'when', 'because', 'nor', 'same', 'off', 'is', \"shan't\", \"weren't\", 'am', 'did', 'our', 'isn', 'the', \"haven't\", 'can', 'yours', 'them', 'won', 'at', \"couldn't\", 'its', \"didn't\", \"you'll\", \"hadn't\", 'above', 'been', 'mightn', 'and', 'me', 'we', 'your', 'just', \"aren't\", 'to', 'why', 'these', 'didn', 't', 'how', \"you've\", 'wouldn', 'during', 'if', 'she'}\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89a508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mahendra', 'Singh', 'Dhoni', ',', 'affectionately', 'known', '``', 'Captain', 'Cool', ',', \"''\", 'iconic', 'figure', 'Indian', 'cricket', '.', 'Renowned', 'exceptional', 'leadership', ',', 'agile', 'wicket-keeping', 'skills', ',', 'remarkable', 'ability', 'finish', 'matches', 'bat', ',', 'Dhoni', \"'s\", 'impact', 'sport', 'profound', '.', 'He', 'first', 'captain', 'lead', 'India', 'victory', 'ICC', 'T20', 'World', 'Cup', 'attain', 'top', 'ranking', 'Test', 'cricket', '.', 'Despite', 'immense', 'success', ',', 'Dhoni', 'remained', 'humble', 'down-to-earth', ',', 'earning', 'respect', 'field', '.', 'His', 'retirement', '2020', 'marked', 'end', 'era', ',', 'leaving', 'behind', 'lasting', 'legacy', 'continues', 'inspire', 'cricket', 'enthusiasts', 'fans', 'worldwide', ',', 'famous', \"''\", 'helicopter', 'shot', \"''\", 'Chennai', 'Super', 'Kings', \"'\", 'successes', 'IPL', 'adding', 'legendary', 'status', '.']\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(sample_text)\n",
    "\n",
    "filter_sentence = []\n",
    "\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        filter_sentence.append(word)\n",
    "    \n",
    "print(filter_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cb54d",
   "metadata": {},
   "source": [
    "# 3. Stemming \n",
    "\n",
    "This is known as sort of normalizing method. Many variations of words carry the same meaning, other than when tense is involved.\n",
    "\n",
    "The reason why we stem is to shorten the lookup, and normalize sentences.\n",
    "\n",
    "Eg: I was taking a ride in the car. I was riding in the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b08bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0293f130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "phthone\n",
      "pythonli\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "sam_words = [\"python\", \"pythoner\", \"pythoning\", \"phthoned\", \"pythonly\"]\n",
    "\n",
    "for word in sam_words:\n",
    "    print(ps.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c01c4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'veri',\n",
       " 'import',\n",
       " 'to',\n",
       " 'be',\n",
       " 'pythoniy',\n",
       " 'while',\n",
       " 'you',\n",
       " 'are',\n",
       " 'python',\n",
       " 'with',\n",
       " 'python',\n",
       " '.',\n",
       " 'all',\n",
       " 'python',\n",
       " 'have',\n",
       " 'python',\n",
       " 'poorli',\n",
       " 'atleast',\n",
       " 'onc',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam = \"It is very important to be pythoniy while you are pythoning with python. All pythoners have pythoned poorly atleast once.\"\n",
    "\n",
    "words = word_tokenize(sam)\n",
    "\n",
    "output = []\n",
    "\n",
    "for word in words:\n",
    "    output.append(ps.stem(word))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bc3f1",
   "metadata": {},
   "source": [
    "# 4. Part of speech tagging \n",
    "\n",
    "Labeling the words as sentences and nouns, adejectives, verbs etc. Even more impressive, it also labels by tense and more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e9c6b",
   "metadata": {},
   "source": [
    "#### POS tag list:\n",
    "\n",
    "CC coordinating conjunction\n",
    "\n",
    "CD cardinal digit\n",
    "\n",
    "DT determiner\n",
    "\n",
    "EX existential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "\n",
    "FW foreign word\n",
    "\n",
    "IN preposition/subordinating conjunction\n",
    "\n",
    "JJ adjective 'big'\n",
    "\n",
    "JJR adjective, comparative 'bigger'\n",
    "\n",
    "JJS adjective, superlative 'biggest'\n",
    "LS list marker 1)\n",
    "MD modal could, will\n",
    "\n",
    "NN noun, singular 'desk'\n",
    "\n",
    "NNS noun plural 'desks'\n",
    "\n",
    "NNP proper noun, singular 'Harrison'\n",
    "\n",
    "NNPS proper noun, plural 'Americans'\n",
    "\n",
    "PDT predeterminer 'all the kids'\n",
    "\n",
    "POS possessive ending parent\\'s\n",
    "\n",
    "PRP personal pronoun I, he, she\n",
    "\n",
    "RB adverb very, silently,\n",
    "\n",
    "RBR adverb, comparative better\n",
    "\n",
    "RBS adverb, superlative best\n",
    "RP particle give up\n",
    "\n",
    "TO to go 'to' the store.\n",
    "\n",
    "UH interjection errrrrrrrm\n",
    "\n",
    "VB verb, base form take\n",
    "\n",
    "VBD verb, past tense took\n",
    "\n",
    "VBG verb, gerund/present participle taking\n",
    "\n",
    "VBN verb, past participle taken\n",
    "\n",
    "VBP verb, sing. present, non-3d take\n",
    "\n",
    "VBZ verb, 3rd person sing. present takes\n",
    "\n",
    "WDT wh-determiner which\n",
    "\n",
    "WP wh-pronoun who, what\n",
    "\n",
    "WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4008a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6adb07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"Engineers, as practitioners of engineering, are professionals who invent, design, analyze, build and test machines, complex systems, structures, gadgets and materials to fulfill functional objectives and requirements while considering the limitations imposed by practicality, regulation, safety and cost.[1][2] The word engineer (Latin ingeniator[3]) is derived from the Latin words ingeniare (to create, generate, contrive, devise and ingenium) (cleverness).[4][5] The foundational qualifications of an engineer typically include a four-year bachelor's degree in an engineering discipline, or in some jurisdictions, a master's degree in an engineering discipline plus four to six years of peer-reviewed professional practice (culminating in a project report or thesis) and passage of engineering board examinations.The work of engineers forms the link between scientific discoveries and their subsequent applications to human and business needs and quality of life.[1]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16e883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States, in the 1970s. NLP's creators claim there is a connection between neurological processes (neuro-), language (linguistic) and behavioral patterns learned through experience (programming), and that these can be changed to achieve specific goals in life.[1][2]: 2  Bandler and Grinder also claim that NLP methodology can model the skills of exceptional people, allowing anyone to acquire those skills.[3]: 5–6 [4] They claim as well that, often in a single session, NLP can treat problems such as phobias, depression, tic disorders, psychosomatic illnesses, near-sightedness,[5] allergy, the common cold,[Note 1] and learning disorders.[7][8] NLP has been adopted by some hypnotherapists and also by companies that run seminars marketed as leadership training to businesses and government agencies.[9][10]There is no scientific evidence supporting the claims made by NLP advocates, and it has been discredited as a pseudoscience.[11][12][13] Scientific reviews state that NLP is based on outdated metaphors of how the brain works that are inconsistent with current neurological theory and contain numerous factual errors. [10][14] Reviews also found that all of the supportive research on NLP contained significant methodological flaws and that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, Grinder, and other NLP practitioners.[12][13]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a3684ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_sentence_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "\n",
    "tokenized = custom_sentence_tokenizer.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9f0b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Neuro-linguistic programming (NLP) is a pseudoscientific approach to communication, personal development, and psychotherapy created by Richard Bandler and John Grinder in California, United States, in the 1970s.',\n",
       " \"NLP's creators claim there is a connection between neurological processes (neuro-), language (linguistic) and behavioral patterns learned through experience (programming), and that these can be changed to achieve specific goals in life.\",\n",
       " '[1][2]:\\u200a2\\u200a Bandler and Grinder also claim that NLP methodology can model the skills of exceptional people, allowing anyone to acquire those skills.',\n",
       " '[3]:\\u200a5–6\\u200a[4] They claim as well that, often in a single session, NLP can treat problems such as phobias, depression, tic disorders, psychosomatic illnesses, near-sightedness,[5] allergy, the common cold,[Note 1] and learning disorders.',\n",
       " '[7][8] NLP has been adopted by some hypnotherapists and also by companies that run seminars marketed as leadership training to businesses and government agencies.',\n",
       " '[9][10]There is no scientific evidence supporting the claims made by NLP advocates, and it has been discredited as a pseudoscience.',\n",
       " '[11][12][13] Scientific reviews state that NLP is based on outdated metaphors of how the brain works that are inconsistent with current neurological theory and contain numerous factual errors.',\n",
       " '[10][14] Reviews also found that all of the supportive research on NLP contained significant methodological flaws and that there were three times as many studies of a much higher quality that failed to reproduce the extraordinary claims made by Bandler, Grinder, and other NLP practitioners.',\n",
       " '[12][13]']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdda8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Neuro-linguistic', 'JJ'), ('programming', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('pseudoscientific', 'JJ'), ('approach', 'NN'), ('to', 'TO'), ('communication', 'NN'), (',', ','), ('personal', 'JJ'), ('development', 'NN'), (',', ','), ('and', 'CC'), ('psychotherapy', 'RB'), ('created', 'VBN'), ('by', 'IN'), ('Richard', 'NNP'), ('Bandler', 'NNP'), ('and', 'CC'), ('John', 'NNP'), ('Grinder', 'NNP'), ('in', 'IN'), ('California', 'NNP'), (',', ','), ('United', 'NNP'), ('States', 'NNPS'), (',', ','), ('in', 'IN'), ('the', 'DT'), ('1970s', 'CD'), ('.', '.')]\n",
      "[('NLP', 'NNP'), (\"'s\", 'POS'), ('creators', 'NNS'), ('claim', 'VBP'), ('there', 'EX'), ('is', 'VBZ'), ('a', 'DT'), ('connection', 'NN'), ('between', 'IN'), ('neurological', 'JJ'), ('processes', 'NNS'), ('(', '('), ('neuro-', 'JJ'), (')', ')'), (',', ','), ('language', 'NN'), ('(', '('), ('linguistic', 'JJ'), (')', ')'), ('and', 'CC'), ('behavioral', 'JJ'), ('patterns', 'NNS'), ('learned', 'VBD'), ('through', 'IN'), ('experience', 'NN'), ('(', '('), ('programming', 'VBG'), (')', ')'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('these', 'DT'), ('can', 'MD'), ('be', 'VB'), ('changed', 'VBN'), ('to', 'TO'), ('achieve', 'VB'), ('specific', 'JJ'), ('goals', 'NNS'), ('in', 'IN'), ('life', 'NN'), ('.', '.')]\n",
      "[('[', 'RB'), ('1', 'CD'), (']', 'JJ'), ('[', '$'), ('2', 'CD'), (']', 'NN'), (':', ':'), ('2', 'CD'), ('Bandler', 'NNP'), ('and', 'CC'), ('Grinder', 'NNP'), ('also', 'RB'), ('claim', 'VBP'), ('that', 'IN'), ('NLP', 'NNP'), ('methodology', 'NN'), ('can', 'MD'), ('model', 'VB'), ('the', 'DT'), ('skills', 'NNS'), ('of', 'IN'), ('exceptional', 'JJ'), ('people', 'NNS'), (',', ','), ('allowing', 'VBG'), ('anyone', 'NN'), ('to', 'TO'), ('acquire', 'VB'), ('those', 'DT'), ('skills', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('3', 'CD'), (']', 'NNS'), (':', ':'), ('5–6', 'CD'), ('[', '$'), ('4', 'CD'), (']', 'NN'), ('They', 'PRP'), ('claim', 'VBP'), ('as', 'RB'), ('well', 'RB'), ('that', 'IN'), (',', ','), ('often', 'RB'), ('in', 'IN'), ('a', 'DT'), ('single', 'JJ'), ('session', 'NN'), (',', ','), ('NLP', 'NNP'), ('can', 'MD'), ('treat', 'VB'), ('problems', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('phobias', 'NNS'), (',', ','), ('depression', 'NN'), (',', ','), ('tic', 'JJ'), ('disorders', 'NNS'), (',', ','), ('psychosomatic', 'JJ'), ('illnesses', 'NNS'), (',', ','), ('near-sightedness', 'JJ'), (',', ','), ('[', 'JJ'), ('5', 'CD'), (']', 'NN'), ('allergy', 'NN'), (',', ','), ('the', 'DT'), ('common', 'JJ'), ('cold', 'NN'), (',', ','), ('[', 'NNP'), ('Note', 'NNP'), ('1', 'CD'), (']', 'NN'), ('and', 'CC'), ('learning', 'NN'), ('disorders', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('7', 'CD'), (']', 'JJ'), ('[', '$'), ('8', 'CD'), (']', 'NNP'), ('NLP', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('adopted', 'VBN'), ('by', 'IN'), ('some', 'DT'), ('hypnotherapists', 'NNS'), ('and', 'CC'), ('also', 'RB'), ('by', 'IN'), ('companies', 'NNS'), ('that', 'WDT'), ('run', 'VBP'), ('seminars', 'RB'), ('marketed', 'VBN'), ('as', 'IN'), ('leadership', 'NN'), ('training', 'NN'), ('to', 'TO'), ('businesses', 'NNS'), ('and', 'CC'), ('government', 'NN'), ('agencies', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('9', 'CD'), (']', 'JJ'), ('[', '$'), ('10', 'CD'), (']', 'NN'), ('There', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('scientific', 'JJ'), ('evidence', 'NN'), ('supporting', 'VBG'), ('the', 'DT'), ('claims', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('NLP', 'NNP'), ('advocates', 'NNS'), (',', ','), ('and', 'CC'), ('it', 'PRP'), ('has', 'VBZ'), ('been', 'VBN'), ('discredited', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('pseudoscience', 'NN'), ('.', '.')]\n",
      "[('[', 'RB'), ('11', 'CD'), (']', 'JJ'), ('[', '$'), ('12', 'CD'), (']', 'NNP'), ('[', 'VBD'), ('13', 'CD'), (']', 'NNP'), ('Scientific', 'NNP'), ('reviews', 'VBZ'), ('state', 'NN'), ('that', 'IN'), ('NLP', 'NNP'), ('is', 'VBZ'), ('based', 'VBN'), ('on', 'IN'), ('outdated', 'JJ'), ('metaphors', 'NNS'), ('of', 'IN'), ('how', 'WRB'), ('the', 'DT'), ('brain', 'NN'), ('works', 'VBZ'), ('that', 'WDT'), ('are', 'VBP'), ('inconsistent', 'JJ'), ('with', 'IN'), ('current', 'JJ'), ('neurological', 'JJ'), ('theory', 'NN'), ('and', 'CC'), ('contain', 'VBP'), ('numerous', 'JJ'), ('factual', 'JJ'), ('errors', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('10', 'CD'), (']', 'JJ'), ('[', '$'), ('14', 'CD'), (']', 'NNP'), ('Reviews', 'NNP'), ('also', 'RB'), ('found', 'VBD'), ('that', 'IN'), ('all', 'DT'), ('of', 'IN'), ('the', 'DT'), ('supportive', 'JJ'), ('research', 'NN'), ('on', 'IN'), ('NLP', 'NNP'), ('contained', 'VBD'), ('significant', 'JJ'), ('methodological', 'JJ'), ('flaws', 'NNS'), ('and', 'CC'), ('that', 'IN'), ('there', 'EX'), ('were', 'VBD'), ('three', 'CD'), ('times', 'NNS'), ('as', 'IN'), ('many', 'JJ'), ('studies', 'NNS'), ('of', 'IN'), ('a', 'DT'), ('much', 'JJ'), ('higher', 'JJR'), ('quality', 'NN'), ('that', 'WDT'), ('failed', 'VBD'), ('to', 'TO'), ('reproduce', 'VB'), ('the', 'DT'), ('extraordinary', 'JJ'), ('claims', 'NNS'), ('made', 'VBN'), ('by', 'IN'), ('Bandler', 'NNP'), (',', ','), ('Grinder', 'NNP'), (',', ','), ('and', 'CC'), ('other', 'JJ'), ('NLP', 'NNP'), ('practitioners', 'NNS'), ('.', '.')]\n",
      "[('[', 'RB'), ('12', 'CD'), (']', 'JJ'), ('[', '$'), ('13', 'CD'), (']', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for word in tokenized:\n",
    "            words = nltk.word_tokenize(word)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            print(tagged)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "process_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb07ee5",
   "metadata": {},
   "source": [
    "# 5. Chunking\n",
    "\n",
    "Group the words in to meaningful chunks. Main goals of chunking is \"Noun phrases\". These are phrases of one or more words that contain a noun, maybe some descriptive words, maybe a verb, and maybe something like an adverb. The idea is to group nouns with tht words that are relation to them.\n",
    "\n",
    "In order to chunk, we combine the part of speech tags wth regular expression. Mainly from regular expression, we are going to utilize the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52dd8e",
   "metadata": {},
   "source": [
    "### _Identifier_\n",
    "\n",
    "1. \\d - any number\n",
    "2. \\D - anything but a number\n",
    "3. \\s - space\n",
    "4. \\S - anything but a space\n",
    "5. \\w - any letter \n",
    "6. \\W - anything but a letter\n",
    "7. . - any character, except for a new line\n",
    "8. \\b - space around whole words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de53a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  Neuro-linguistic/JJ\n",
      "  programming/NN\n",
      "  (/(\n",
      "  (Chunk NLP/NNP)\n",
      "  )/)\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  pseudoscientific/JJ\n",
      "  approach/NN\n",
      "  to/TO\n",
      "  communication/NN\n",
      "  ,/,\n",
      "  personal/JJ\n",
      "  development/NN\n",
      "  ,/,\n",
      "  and/CC\n",
      "  psychotherapy/RB\n",
      "  created/VBN\n",
      "  by/IN\n",
      "  (Chunk Richard/NNP Bandler/NNP)\n",
      "  and/CC\n",
      "  (Chunk John/NNP Grinder/NNP)\n",
      "  in/IN\n",
      "  (Chunk California/NNP)\n",
      "  ,/,\n",
      "  (Chunk United/NNP)\n",
      "  States/NNPS\n",
      "  ,/,\n",
      "  in/IN\n",
      "  the/DT\n",
      "  1970s/CD\n",
      "  ./.)\n",
      "(S\n",
      "  (Chunk NLP/NNP)\n",
      "  's/POS\n",
      "  creators/NNS\n",
      "  claim/VBP\n",
      "  there/EX\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  connection/NN\n",
      "  between/IN\n",
      "  neurological/JJ\n",
      "  processes/NNS\n",
      "  (/(\n",
      "  neuro-/JJ\n",
      "  )/)\n",
      "  ,/,\n",
      "  language/NN\n",
      "  (/(\n",
      "  linguistic/JJ\n",
      "  )/)\n",
      "  and/CC\n",
      "  behavioral/JJ\n",
      "  patterns/NNS\n",
      "  learned/VBD\n",
      "  through/IN\n",
      "  experience/NN\n",
      "  (/(\n",
      "  programming/VBG\n",
      "  )/)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  that/IN\n",
      "  these/DT\n",
      "  can/MD\n",
      "  be/VB\n",
      "  changed/VBN\n",
      "  to/TO\n",
      "  achieve/VB\n",
      "  specific/JJ\n",
      "  goals/NNS\n",
      "  in/IN\n",
      "  life/NN\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  1/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  2/CD\n",
      "  ]/NN\n",
      "  :/:\n",
      "  2/CD\n",
      "  (Chunk Bandler/NNP)\n",
      "  and/CC\n",
      "  (Chunk Grinder/NNP)\n",
      "  also/RB\n",
      "  claim/VBP\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP methodology/NN)\n",
      "  can/MD\n",
      "  model/VB\n",
      "  the/DT\n",
      "  skills/NNS\n",
      "  of/IN\n",
      "  exceptional/JJ\n",
      "  people/NNS\n",
      "  ,/,\n",
      "  allowing/VBG\n",
      "  anyone/NN\n",
      "  to/TO\n",
      "  acquire/VB\n",
      "  those/DT\n",
      "  skills/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  3/CD\n",
      "  ]/NNS\n",
      "  :/:\n",
      "  5–6/CD\n",
      "  [/$\n",
      "  4/CD\n",
      "  ]/NN\n",
      "  They/PRP\n",
      "  claim/VBP\n",
      "  as/RB\n",
      "  well/RB\n",
      "  that/IN\n",
      "  ,/,\n",
      "  often/RB\n",
      "  in/IN\n",
      "  a/DT\n",
      "  single/JJ\n",
      "  session/NN\n",
      "  ,/,\n",
      "  (Chunk NLP/NNP)\n",
      "  can/MD\n",
      "  treat/VB\n",
      "  problems/NNS\n",
      "  such/JJ\n",
      "  as/IN\n",
      "  phobias/NNS\n",
      "  ,/,\n",
      "  depression/NN\n",
      "  ,/,\n",
      "  tic/JJ\n",
      "  disorders/NNS\n",
      "  ,/,\n",
      "  psychosomatic/JJ\n",
      "  illnesses/NNS\n",
      "  ,/,\n",
      "  near-sightedness/JJ\n",
      "  ,/,\n",
      "  [/JJ\n",
      "  5/CD\n",
      "  ]/NN\n",
      "  allergy/NN\n",
      "  ,/,\n",
      "  the/DT\n",
      "  common/JJ\n",
      "  cold/NN\n",
      "  ,/,\n",
      "  (Chunk [/NNP Note/NNP)\n",
      "  1/CD\n",
      "  ]/NN\n",
      "  and/CC\n",
      "  learning/NN\n",
      "  disorders/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  7/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  8/CD\n",
      "  (Chunk ]/NNP NLP/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  adopted/VBN\n",
      "  by/IN\n",
      "  some/DT\n",
      "  hypnotherapists/NNS\n",
      "  and/CC\n",
      "  also/RB\n",
      "  by/IN\n",
      "  companies/NNS\n",
      "  that/WDT\n",
      "  run/VBP\n",
      "  seminars/RB\n",
      "  marketed/VBN\n",
      "  as/IN\n",
      "  leadership/NN\n",
      "  training/NN\n",
      "  to/TO\n",
      "  businesses/NNS\n",
      "  and/CC\n",
      "  government/NN\n",
      "  agencies/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  9/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  10/CD\n",
      "  ]/NN\n",
      "  There/EX\n",
      "  is/VBZ\n",
      "  no/DT\n",
      "  scientific/JJ\n",
      "  evidence/NN\n",
      "  supporting/VBG\n",
      "  the/DT\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  advocates/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  it/PRP\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  discredited/VBN\n",
      "  as/IN\n",
      "  a/DT\n",
      "  pseudoscience/NN\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  11/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  12/CD\n",
      "  (Chunk ]/NNP)\n",
      "  [/VBD\n",
      "  13/CD\n",
      "  (Chunk ]/NNP Scientific/NNP)\n",
      "  reviews/VBZ\n",
      "  state/NN\n",
      "  that/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  is/VBZ\n",
      "  based/VBN\n",
      "  on/IN\n",
      "  outdated/JJ\n",
      "  metaphors/NNS\n",
      "  of/IN\n",
      "  how/WRB\n",
      "  the/DT\n",
      "  brain/NN\n",
      "  works/VBZ\n",
      "  that/WDT\n",
      "  are/VBP\n",
      "  inconsistent/JJ\n",
      "  with/IN\n",
      "  current/JJ\n",
      "  neurological/JJ\n",
      "  theory/NN\n",
      "  and/CC\n",
      "  contain/VBP\n",
      "  numerous/JJ\n",
      "  factual/JJ\n",
      "  errors/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  [/RB\n",
      "  10/CD\n",
      "  ]/JJ\n",
      "  [/$\n",
      "  14/CD\n",
      "  (Chunk ]/NNP Reviews/NNP)\n",
      "  also/RB\n",
      "  found/VBD\n",
      "  that/IN\n",
      "  all/DT\n",
      "  of/IN\n",
      "  the/DT\n",
      "  supportive/JJ\n",
      "  research/NN\n",
      "  on/IN\n",
      "  (Chunk NLP/NNP)\n",
      "  contained/VBD\n",
      "  significant/JJ\n",
      "  methodological/JJ\n",
      "  flaws/NNS\n",
      "  and/CC\n",
      "  that/IN\n",
      "  there/EX\n",
      "  were/VBD\n",
      "  three/CD\n",
      "  times/NNS\n",
      "  as/IN\n",
      "  many/JJ\n",
      "  studies/NNS\n",
      "  of/IN\n",
      "  a/DT\n",
      "  much/JJ\n",
      "  higher/JJR\n",
      "  quality/NN\n",
      "  that/WDT\n",
      "  failed/VBD\n",
      "  to/TO\n",
      "  reproduce/VB\n",
      "  the/DT\n",
      "  extraordinary/JJ\n",
      "  claims/NNS\n",
      "  made/VBN\n",
      "  by/IN\n",
      "  (Chunk Bandler/NNP)\n",
      "  ,/,\n",
      "  (Chunk Grinder/NNP)\n",
      "  ,/,\n",
      "  and/CC\n",
      "  other/JJ\n",
      "  (Chunk NLP/NNP)\n",
      "  practitioners/NNS\n",
      "  ./.)\n",
      "(S [/RB 12/CD ]/JJ [/$ 13/CD ]/NN)\n"
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\" \n",
    "            \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            print(chunked)\n",
    "            \n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01f5f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from nltk.draw import TreeWidget\n",
    "from nltk.draw.util import CanvasFrame\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de66018e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m---> 19\u001b[0m process_content()\n",
      "Cell \u001b[1;32mIn[30], line 13\u001b[0m, in \u001b[0;36mprocess_content\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m         chunked \u001b[38;5;241m=\u001b[39m chunkParser\u001b[38;5;241m.\u001b[39mparse(tagged)\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m#print(chunked)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m         chunked\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\nltk\\tree\\tree.py:761\u001b[0m, in \u001b[0;36mTree.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;124;03mOpen a new window containing a graphical diagram of this tree.\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdraw\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m draw_trees\n\u001b[1;32m--> 761\u001b[0m draw_trees(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\nltk\\draw\\tree.py:1008\u001b[0m, in \u001b[0;36mdraw_trees\u001b[1;34m(*trees)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_trees\u001b[39m(\u001b[38;5;241m*\u001b[39mtrees):\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;124;03m    Open a new window containing a graphical diagram of the given\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;124;03m    trees.\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m    :rtype: None\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1008\u001b[0m     TreeView(\u001b[38;5;241m*\u001b[39mtrees)\u001b[38;5;241m.\u001b[39mmainloop()\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\site-packages\\nltk\\draw\\tree.py:998\u001b[0m, in \u001b[0;36mTreeView.mainloop\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_idle():\n\u001b[0;32m    997\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_top\u001b[38;5;241m.\u001b[39mmainloop(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Anaconda\\Lib\\tkinter\\__init__.py:1485\u001b[0m, in \u001b[0;36mMisc.mainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmainloop\u001b[39m(\u001b[38;5;28mself\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1484\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1485\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtk\u001b[38;5;241m.\u001b[39mmainloop(n)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_content():\n",
    "    try:\n",
    "        for i in tokenized:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = nltk.pos_tag(words)\n",
    "            #print(tagged)\n",
    "            \n",
    "            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\" \n",
    "            \n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            #print(chunked)\n",
    "            chunked.draw()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "\n",
    "process_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c28fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
